{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендации товаров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "cc8f0a11-d9b4-48b2-8af4-b41500747c0b",
    "_uuid": "2f249cc6ef4f014a49bb0d114fbeec0afe8c96b3",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # поданобится для линейной алгебры\n",
    "import pandas as pd # CSV I/O + предварительная подготовка выборки\n",
    "from scipy.sparse import vstack # для объединения разреженных матриц\n",
    "from scipy import sparse # для разреженных матриц\n",
    "from scipy.sparse.linalg import spsolve # решение системы линейных уравнений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_tree.csv\n",
      "events.csv\n",
      "item_properties_part1.csv\n",
      "item_properties_part2.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from subprocess import check_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DATA_PATH = \"./retailrocket\"\n",
    "\n",
    "print(check_output([\"ls\", DATA_PATH]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "8b5039de-2337-4424-9872-c4c05385df48",
    "_uuid": "0371c8f7a46066ee6d79432bba7426068c6dae7c",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events = pd.read_csv(DATA_PATH + '/events.csv')\n",
    "category_tree = pd.read_csv(DATA_PATH + '/category_tree.csv')\n",
    "items1 = pd.read_csv(DATA_PATH + '/item_properties_part1.csv')\n",
    "items2 = pd.read_csv(DATA_PATH + '/item_properties_part2.csv')\n",
    "items = pd.concat([items1, items2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "54f117a6-9db8-4dce-85c8-de5ed8f7f63f",
    "_uuid": "35814dee33a59a6eb1621c7cb1c65dc04fdb900b"
   },
   "source": [
    "# Создаем user-item матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "39af0516-f258-4c0a-ab30-81aa8fc10c05",
    "_uuid": "148d08bd3ca27e964cabc1fd77341d9a885c035b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_users = events['visitorid'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "1c093df2-f5cf-4c47-b1db-21985410a893",
    "_uuid": "d242b900d8898a34979515ae16324c04598e5b05",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_items = items['itemid'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "fb2ea817-f8ad-40ac-aada-4c3efc7453c4",
    "_uuid": "5df7cdbe869ec5a0cf0ac61ee3445ec654e5ebe5",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407580 466866\n"
     ]
    }
   ],
   "source": [
    "print (str(n_users) +\" \" +  str(n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "640411ce-a5ab-40bc-b928-a7be4a2437f1",
    "_uuid": "543e75df2f9cc1c101e750d728f626d766e55ce3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_to_item_matrix = sparse.dok_matrix((n_users+1, n_items+2), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "2da7c395-a680-4b8b-9c58-3c8148a1af66",
    "_uuid": "14b6837541c5ec680ebc974d87f84f9b0325abd5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Заполняем матрицу весами событий\n",
    "\n",
    "action_weights = {'view': 1, 'addtocart': 2, 'transaction': 3}\n",
    "for row in events.itertuples():\n",
    "    mapped_user_key = row[2]\n",
    "    event_type = row.event\n",
    "    if event_type in action_weights.keys():\n",
    "            user_to_item_matrix[mapped_user_key, row[4]] = action_weights[event_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "2a807afb-f660-47cc-98d2-7a83fb3a0996",
    "_uuid": "76919903392744ddb0d52788da60cbb17e2da68a",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1407581, 466868)\n"
     ]
    }
   ],
   "source": [
    "user_to_item_matrix = user_to_item_matrix.tocsr()\n",
    "print(user_to_item_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a975c0e2-0b64-46d7-87b1-ce7a83fd95ba",
    "_uuid": "3413418ff8dd936b1acb204496201126e3d15ef6"
   },
   "source": [
    "# Разбиваем на обучение и тест"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим сначала на разреженность матрицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "009bde3b-63e8-4ae3-9c77-b85f51467254",
    "_uuid": "d62bd82d0b7649ca91311895d06b066b2fe32afc",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.264344859727226e-06\n"
     ]
    }
   ],
   "source": [
    "sparsity = float(len(user_to_item_matrix.nonzero()[0])) # число ненулевых ячеек\n",
    "sparsity /= (user_to_item_matrix.shape[0] * user_to_item_matrix.shape[1]) # размер матрицы\n",
    "print (sparsity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем на обучающую и тестовую выборку по пользователям. Ситуацию, когда добавляются новые товары в этом примере не рассматриваем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "978c76d9-fa7c-4165-bda6-d999b767e540",
    "_uuid": "b4cb6fe62d377c2d435ddc1ba014d5e92f4528f3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(user_to_item_matrix, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "42b1e919-d865-4489-8d13-8518584493f6",
    "_uuid": "5e9a04ee6344368665bc8b4ebd9d8f5f5fea21f0",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1126064, 466868)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "a4dc887c-1726-4cb1-847c-bd646581087b",
    "_uuid": "a1d7f9c5fb773b41f2e69619cbaf9af2329f0b5b",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281517, 466868)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d6c41a32-bbce-42cb-98a6-4ef24f5ad42d",
    "_uuid": "732f4160cb28fd1d2986c6566796fd13cb31fa42"
   },
   "source": [
    "# Похожесть пользователей по косинусной мере\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "4c0db36b-cae1-403d-840d-e2d1b9d414a7",
    "_uuid": "eb5f9e6c0b24967cdd64a58c2001bf83cecb0394",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "2a1753e0-4476-4cd4-a8d7-86ae3dfa26d8",
    "_uuid": "5627ee4eacd8de83c9ec4faecd05f73da18a65c7",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xead/anaconda/envs/py36/lib/python3.6/site-packages/scipy/sparse/compressed.py:774: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "# TODO: this is user to user similarity. check item to item similarity as well\n",
    "cosine_similarity_matrix = cosine_similarity(X_train, X_train, dense_output=False)\n",
    "cosine_similarity_matrix.setdiag(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431965\n"
     ]
    }
   ],
   "source": [
    "one_user_id = 42\n",
    "another_user_id = cosine_similarity_matrix[one_user_id].argmax()\n",
    "print(another_user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 229382)\t1\n",
      "  (0, 333191)\t1\n",
      "  (0, 353334)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X_train[one_user_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 229382)\t1\n",
      "  (0, 333191)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X_train[another_user_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем найти пользователя, который сделал много действий:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "  (0, 2567)\t1\n",
      "  (0, 12057)\t1\n",
      "  (0, 40702)\t1\n",
      "  (0, 80726)\t1\n",
      "  (0, 97651)\t1\n",
      "  (0, 98178)\t1\n",
      "  (0, 174896)\t1\n",
      "  (0, 215063)\t1\n",
      "  (0, 427641)\t1\n",
      "  (0, 457447)\t1\n"
     ]
    }
   ],
   "source": [
    "for i in range(X_train.shape[0]):\n",
    "    if X_train[i, :].sum() > 5:\n",
    "        print(i)\n",
    "        print(X_train[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекомендации на основе implicit ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "a12376a8-e7aa-4a7e-b563-7de37d9052c5",
    "_uuid": "07b6abc19a7263a085dc8c1d05b2a25726ea74be",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def implicit_weighted_ALS(training_set, lambda_val = 0.1, alpha = 40, iterations = 10, rank_size = 20, seed = 0):\n",
    "    '''\n",
    "    Implicit weighted ALS taken from Hu, Koren, and Volinsky 2008. Designed for alternating least squares and implicit\n",
    "    feedback based collaborative filtering. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    training_set - Our matrix of ratings with shape m x n, where m is the number of users and n is the number of items.\n",
    "    Should be a sparse csr matrix to save space. \n",
    "    \n",
    "    lambda_val - Used for regularization during alternating least squares. Increasing this value may increase bias\n",
    "    but decrease variance. Default is 0.1. \n",
    "    \n",
    "    alpha - The parameter associated with the confidence matrix discussed in the paper, where Cui = 1 + alpha*Rui. \n",
    "    The paper found a default of 40 most effective. Decreasing this will decrease the variability in confidence between\n",
    "    various ratings.\n",
    "    \n",
    "    iterations - The number of times to alternate between both user feature vector and item feature vector in\n",
    "    alternating least squares. More iterations will allow better convergence at the cost of increased computation. \n",
    "    The authors found 10 iterations was sufficient, but more may be required to converge. \n",
    "    \n",
    "    rank_size - The number of latent features in the user/item feature vectors. The paper recommends varying this \n",
    "    between 20-200. Increasing the number of features may overfit but could reduce bias. \n",
    "    \n",
    "    seed - Set the seed for reproducible results\n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    The feature vectors for users and items. The dot product of these feature vectors should give you the expected \n",
    "    \"rating\" at each point in your original matrix. \n",
    "    '''\n",
    "    \n",
    "    # first set up our confidence matrix\n",
    "    \n",
    "    conf = (alpha * training_set) # To allow the matrix to stay sparse, I will add one later when each row is taken \n",
    "                                # and converted to dense. \n",
    "    num_user = conf.shape[0]\n",
    "    num_item = conf.shape[1] # Get the size of our original ratings matrix, m x n\n",
    "    \n",
    "    # initialize our X/Y feature vectors randomly with a set seed\n",
    "    rstate = np.random.RandomState(seed)\n",
    "    \n",
    "    X = sparse.csr_matrix(rstate.normal(size = (num_user, rank_size))) # Random numbers in a m x rank shape\n",
    "    Y = sparse.csr_matrix(rstate.normal(size = (num_item, rank_size))) # Normally this would be rank x n but we can \n",
    "                                                                 # transpose at the end. Makes calculation more simple.\n",
    "    X_eye = sparse.eye(num_user)\n",
    "    Y_eye = sparse.eye(num_item)\n",
    "    lambda_eye = lambda_val * sparse.eye(rank_size) # Our regularization term lambda*I. \n",
    "    \n",
    "    # We can compute this before iteration starts. \n",
    "    \n",
    "    # Begin iterations\n",
    "   \n",
    "    for iter_step in range(iterations): # Iterate back and forth between solving X given fixed Y and vice versa\n",
    "        # Compute yTy and xTx at beginning of each iteration to save computing time\n",
    "        yTy = Y.T.dot(Y)\n",
    "        xTx = X.T.dot(X)\n",
    "        \n",
    "        print(iter_step)\n",
    "        \n",
    "        # Being iteration to solve for X based on fixed Y\n",
    "        for u in range(num_user):\n",
    "            if u % 100 == 0:\n",
    "                print(u)\n",
    "            conf_samp = conf[u,:].toarray() # Grab user row from confidence matrix and convert to dense\n",
    "            pref = conf_samp.copy() \n",
    "            pref[pref != 0] = 1 # Create binarized preference vector \n",
    "            \n",
    "            CuI = sparse.diags(conf_samp, [0]) # Get Cu - I term, don't need to subtract 1 since we never added it \n",
    "            yTCuIY = Y.T.dot(CuI).dot(Y) # This is the yT(Cu-I)Y term \n",
    "            yTCupu = Y.T.dot(CuI + Y_eye).dot(pref.T) # This is the yTCuPu term, where we add the eye back in\n",
    "                                                      # Cu - I + I = Cu\n",
    "                \n",
    "            X[u] = spsolve(yTy + yTCuIY + lambda_eye, yTCupu) \n",
    "            # Solve for Xu = ((yTy + yT(Cu-I)Y + lambda*I)^-1)yTCuPu, equation 4 from the paper  \n",
    "        \n",
    "        # Begin iteration to solve for Y based on fixed X \n",
    "        for i in range(num_item):\n",
    "            conf_samp = conf[:,i].T.toarray() # transpose to get it in row format and convert to dense\n",
    "            pref = conf_samp.copy()\n",
    "            pref[pref != 0] = 1 # Create binarized preference vector\n",
    "            \n",
    "            CiI = sparse.diags(conf_samp, [0]) # Get Ci - I term, don't need to subtract 1 since we never added it\n",
    "            xTCiIX = X.T.dot(CiI).dot(X) # This is the xT(Cu-I)X term\n",
    "            xTCiPi = X.T.dot(CiI + X_eye).dot(pref.T) # This is the xTCiPi term\n",
    "            \n",
    "            Y[i] = spsolve(xTx + xTCiIX + lambda_eye, xTCiPi)\n",
    "            # Solve for Yi = ((xTx + xT(Cu-I)X) + lambda*I)^-1)xTCiPi, equation 5 from the paper\n",
    "    \n",
    "    # End iterations\n",
    "    return X, Y.T # Transpose at the end to make up for not being transposed at the beginning. \n",
    "                         # Y needs to be rank x n. Keep these as separate matrices for scale reasons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c6a50430-e2e9-42a7-8fda-7966d72aadeb",
    "_uuid": "e6f9d21c5b28ef91af6a4dcf03c38b94ed30391d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! pip install implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "a0be1b12-9e8d-49cf-974f-8d149ce95577",
    "_uuid": "6f6fe919f181856eac32f3bcf4010cd7a8264f42",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-41f41974b9a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m user_vecs, item_vecs = implicit_weighted_ALS(X_train, lambda_val = 0.1, alpha = 15, iterations = 1,\n\u001b[0;32m----> 2\u001b[0;31m                                             rank_size = 20)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-c4add536c604>\u001b[0m in \u001b[0;36mimplicit_weighted_ALS\u001b[0;34m(training_set, lambda_val, alpha, iterations, rank_size, seed)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mCuI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_samp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Get Cu - I term, don't need to subtract 1 since we never added it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0myTCuIY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCuI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This is the yT(Cu-I)Y term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0myTCupu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCuI\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mY_eye\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This is the yTCuPu term, where we add the eye back in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                                                       \u001b[0;31m# Cu - I + I = Cu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xead/anaconda/envs/py36/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \"\"\"\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xead/anaconda/envs/py36/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xead/anaconda/envs/py36/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    531\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m            indptr)\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0mnnz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindptr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "user_vecs, item_vecs = implicit_weighted_ALS(X_train, lambda_val = 0.1, alpha = 15, iterations = 1,\n",
    "                                            rank_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1126064, 466868)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6719955a-cd21-41df-8824-00c97bba39b3",
    "_uuid": "33c6b4af517b0f1fc1bc3724a73ac0680b8ba30b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_n(row_data, row_indices, n):\n",
    "        i = row_data.argsort()[-n:]\n",
    "        # i = row_data.argpartition(-n)[-n:]\n",
    "        top_values = row_data[i]\n",
    "        top_indices = row_indices[i]\n",
    "        return top_values, top_indices, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9de67428-bbf8-411e-937a-5a39c6739121",
    "_uuid": "3af79ba586c58437686dd9dbefbed9d2bc1d30d3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_topk(ratings, similarity, kind='user', k=40):\n",
    "    pred = sparse.csr_matrix((0,ratings.shape[1]), dtype=np.int8)\n",
    "    if kind == 'user':\n",
    "        for i in range(similarity.shape[0]):\n",
    "            top_k_values, top_k_users = max_n(np.array(similarity.data[i]),np.array(similarity.rows[i]),k)[:2]\n",
    "            current = top_k_values.reshape(1,-1).dot(ratings[top_k_users].todense())\n",
    "            current /= np.sum(np.abs(top_k_values))+1\n",
    "            vstack([pred, current])\n",
    "    if kind == 'item':\n",
    "        for j in range(ratings.shape[1]):\n",
    "            top_k_items = [np.argsort(similarity[:,j])[:-k-1:-1]]\n",
    "            for i in range(ratings.shape[0]):\n",
    "                pred[i, j] = similarity[j, :][top_k_items].dot(ratings[i, :][top_k_items].T) \n",
    "                pred[i, j] /= np.sum(np.abs(similarity[j, :][top_k_items]))        \n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cosine_similarity_matrix_ll=cosine_similarity_matrix.tolil()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "582daa1c-82d3-42cd-81b8-ca0ca6e58ac1",
    "_uuid": "d7a40c5c861b096719e1e5635bb19854c0058afd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = predict_topk(X_train, cosine_similarity_matrix_ll, kind='user', k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Попробовать построить простые рекомендации на основе user-based подхода (по косинусной мере или по корреляции Пирсона)\n",
    "1. ** Попробовать запустить ALS на небольшой подвыборке пользователей (например, на 5-10 тысячах)\n",
    "1. ** Попробовать написать рекомендации на основе матричного разложения, выполненного с помощью SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
